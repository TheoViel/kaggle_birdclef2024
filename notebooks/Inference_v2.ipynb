{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tviel/work/kaggle_birdclef_2024/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tviel/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tviel/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from util.logger import Config\n",
    "from util.metrics import macro_auc\n",
    "from util.torch import load_model_weights\n",
    "\n",
    "from data.dataset import WaveInfDataset\n",
    "from data.preparation import prepare_data, prepare_folds\n",
    "from data.processing import create_target_path, ProgressParallel, get_load_librosa_save_h5py\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from inference.predict import predict\n",
    "\n",
    "from params import CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    DATA_PATH = \"../input/train_audio/\"\n",
    "else:\n",
    "    DATA_PATH = \"../input/unlabeled_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "DEVICE = \"cpu\" \n",
    "RUNTIME = \"openvino\"\n",
    "\n",
    "DURATION = 5\n",
    "SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 if EVAL else \"fullfit_0\"\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    # (\"../logs/2024-04-12/8/\", [FOLD]),   # LB 0.64 baseline\n",
    "    # (\"../logs/2024-04-18/12/\", [FOLD]),  #\n",
    "    # (\"../logs/2024-04-18/15/\", [FOLD]),  #\n",
    "    # (\"../logs/2024-04-19/4/\", [FOLD]),  # Change norm, sampling\n",
    "    # (\"../logs/2024-04-19/5/\", [FOLD]),  # d=15s\n",
    "    # (\"../logs/2024-04-19/7/\", [FOLD]),  # minmaxnorm, sampling, nocall, less mix\n",
    "    # (\"../logs/2024-04-19/8/\", [FOLD]),  # minmaxnorm, no sampling, nocall, less mix no add\n",
    "    # (\"../logs/2024-04-19/10/\", [FOLD]),  # minmaxnorm more mix more aug\n",
    "    # (\"../logs/2024-04-29/2/\", [FOLD]),  # minmaxnorm fixed crop\n",
    "    # (\"../logs/2024-04-29/4/\", [FOLD]),  # minmaxnorm fixed crop 20s selfmix\n",
    "    # (\"../logs/2024-04-29/6/\", [FOLD]),  # minmaxnorm fixed crop no_xc selfmix\n",
    "    # (\"../logs/2024-04-29/7/\", [FOLD]),  # minmaxnorm fixed crop no_xc selfmix focal_bce ousmk\n",
    "    # (\"../logs/2024-04-30/0/\", [FOLD]),  # minmaxnorm selfmix focal_bce ousmk\n",
    "    # (\"../logs/2024-04-30/1/\", [FOLD]),  # minmaxnorm selfmix focal_bce ousmk++\n",
    "    # (\"../logs/2024-04-30/3/\", [FOLD]),  # minmaxnorm selfmix focal_bce no_xc more mix\n",
    "    # (\"../logs/2024-04-30/4/\", [FOLD]),  # minmaxnorm selfmix bce no_xc ousmk^\n",
    "    # (\"../logs/2024-05-02/0/\", [FOLD]),  # selfmix focal_bce ousmk + dedup, new melspec params, start-end sampling\n",
    "    (\"../logs/2024-05-02/15/\", [FOLD]),  # no selfmix focal_bce ousmk + 2nd mask, new melspec params, start-end sampling\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     [f for f, _ in EXP_FOLDERS],\n",
    "#     directory=\"../output/dataset_1/\",\n",
    "#     dataset_name=\"BirdCLEF 2024 Weights 1\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*/*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "\n",
    "    folds = pd.read_csv('../input/folds_4.csv')\n",
    "    folds['id'] = folds['filename'].apply(lambda x: x.split('/')[-1][:-4])\n",
    "    df = df.merge(folds)\n",
    "    df = df[df['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "    df[\"primary_label\"] = df[\"path\"].apply(lambda x:  x.split('/')[-2])\n",
    "else:\n",
    "    df = pd.DataFrame({\"path\": glob.glob(DATA_PATH + \"*\")})\n",
    "    df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "    \n",
    "    df[\"duration\"] = df[\"path\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "    df = df[df[\"duration\"] == 240].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/unlabeled_soundscapes/184575141.ogg</td>\n",
       "      <td>184575141</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/unlabeled_soundscapes/1542255759.ogg</td>\n",
       "      <td>1542255759</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/unlabeled_soundscapes/1976786596.ogg</td>\n",
       "      <td>1976786596</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/unlabeled_soundscapes/106748716.ogg</td>\n",
       "      <td>106748716</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/unlabeled_soundscapes/523220948.ogg</td>\n",
       "      <td>523220948</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path          id  duration\n",
       "0   ../input/unlabeled_soundscapes/184575141.ogg   184575141     240.0\n",
       "1  ../input/unlabeled_soundscapes/1542255759.ogg  1542255759     240.0\n",
       "2  ../input/unlabeled_soundscapes/1976786596.ogg  1976786596     240.0\n",
       "3   ../input/unlabeled_soundscapes/106748716.ogg   106748716     240.0\n",
       "4   ../input/unlabeled_soundscapes/523220948.ogg   523220948     240.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2024-05-02/15/tf_efficientnetv2_s_fullfit_0.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        config.melspec_config,\n",
    "        head=config.head,\n",
    "        aug_config=config.aug_config,\n",
    "        num_classes=config.num_classes,\n",
    "        n_channels=config.n_channels,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        # exportable=True,\n",
    "        verbose=True,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.to(DEVICE).eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1280, 4, 10)\n"
     ]
    }
   ],
   "source": [
    "if RUNTIME != \"torch\":\n",
    "    import onnx\n",
    "    import onnxruntime as ort\n",
    "    from onnxconverter_common import float16\n",
    "\n",
    "    def infer_onnx(ort_session, x, output_names=[\"output\"], input_name=\"x\"):\n",
    "        x = ort_session.run(output_names, {input_name: x.numpy()})[0]\n",
    "        return x\n",
    "\n",
    "    input_names = ['x']\n",
    "    output_names = ['output']\n",
    "\n",
    "    input_tensor = torch.randn(\n",
    "        BATCH_SIZE,\n",
    "        1,\n",
    "        config.melspec_config['n_mels'],\n",
    "        313 if config.melspec_config['hop_length'] == 512 else 224\n",
    "    )\n",
    "\n",
    "    onnx_ckpt_list = []\n",
    "    for models_ in models:\n",
    "        for i, model in enumerate(models_):\n",
    "            torch.onnx.export(\n",
    "                model.encoder,\n",
    "                input_tensor,\n",
    "                f\"model_{i}.onnx\",\n",
    "                verbose=False,\n",
    "                input_names=input_names,\n",
    "                output_names=output_names,\n",
    "                dynamic_axes={\"x\": [0]}\n",
    "            )\n",
    "            onnx_ckpt_list.append(f\"model_{i}.onnx\")\n",
    "\n",
    "\n",
    "    ort_sessions = []\n",
    "    for i in range(len(models)):\n",
    "        onnx_model = onnx.load(f\"model_{i}.onnx\")\n",
    "        # onnx_model = float16.convert_float_to_float16(onnx_model)\n",
    "        # onnx.save(onnx_model, f\"model_{i}.onnx\")\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        ort_session = ort.InferenceSession(f\"model_{i}.onnx\")\n",
    "        ort_sessions.append(ort_session)\n",
    "        \n",
    "    ort_session_2 = ort_sessions[0]\n",
    "    out = ort_session_2.run(output_names, {input_names[0] : input_tensor.numpy()})  # .astype(np.float16)\n",
    "    print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release. Please use OpenVINO Model Converter (OVC). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n",
      "Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/tviel/work/kaggle_birdclef_2024/src/model_0.xml\n",
      "[ SUCCESS ] BIN file: /home/tviel/work/kaggle_birdclef_2024/src/model_0.bin\n"
     ]
    }
   ],
   "source": [
    "if RUNTIME == \"openvino\":\n",
    "    !mo --input_model model_0.onnx # --compress_to_fp16=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNTIME == \"openvino\":\n",
    "    import openvino.runtime as ov\n",
    "    core = ov.Core()\n",
    "    openvino_model = core.read_model(model='model_0.xml')\n",
    "    compiled_model = core.compile_model(openvino_model, device_name=\"CPU\")\n",
    "    infer_request = compiled_model.create_infer_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNTIME = \"openvino\"  # torch openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(path):\n",
    "    wave, sr = librosa.load(path, sr=SR)\n",
    "\n",
    "    if EVAL:\n",
    "        if len(wave) > SR * DURATION:\n",
    "            wave = wave[:SR * DURATION][None]\n",
    "        else:\n",
    "            wave = np.pad(wave, (0, SR * DURATION - len(wave)))[None]\n",
    "    else:\n",
    "        wave = wave.reshape(-1, SR * DURATION)\n",
    "\n",
    "    if config.normalize:\n",
    "        wave = np.array([librosa.util.normalize(w) for w in wave])\n",
    "\n",
    "    wave = torch.from_numpy(wave)\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_sample(wave):\n",
    "    if isinstance(wave, str):\n",
    "        wave = load_sample(wave)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            melspec = model.ft_extractor(wave)[0].unsqueeze(1)\n",
    "\n",
    "        # y_pred = torch.zeros((48, 182))\n",
    "\n",
    "        if RUNTIME == \"openvino\":\n",
    "            fts = infer_request.infer(inputs=[melspec.numpy()])[\"output\"]\n",
    "            y_pred = model.get_logits(torch.from_numpy(fts))\n",
    "        elif RUNTIME == \"onnx\":\n",
    "            fts = infer_onnx(ort_session, melspec)\n",
    "            y_pred = model.get_logits(torch.from_numpy(fts))\n",
    "        else:\n",
    "            with torch.cuda.amp.autocast(enabled=USE_FP16):\n",
    "                fts = model.encoder(melspec)\n",
    "                y_pred = model.get_logits(fts)\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712a29362e23447d96335ad2ba1ad103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waves = joblib.Parallel(n_jobs=4)(  # , backend='loky'\n",
    "    joblib.delayed(load_sample)(path) for path in tqdm(df[\"path\"].values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d11ba8bef774e6ba8d2b9fc2eb15839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # Torch - 2:46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0359fe55a24cc8a188767811bba13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # OV FP16 - 2:11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a29e949c7f477ca74bf98ecf125947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(wave) for wave in tqdm(waves)]  # OV FP32 - 2:11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9965c3cf6b8342b5ae9dd25c8c3a2267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # no model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906386b1a9bd49da8a650f5f637bfb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # no melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3baf92593c43718af01a54343ea557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = [infer_sample(path) for path in tqdm(df[\"path\"].values)]  # only load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a6aebf975b4e86be2b34d5c767a40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_rows = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "\n",
    "    y_pred = all_preds[idx]\n",
    "    preds = expit(y_pred)\n",
    "\n",
    "    for t, pred in enumerate(preds):\n",
    "        predictions = dict([(l, p) for l, p in zip(CLASSES, pred)])\n",
    "        inference_rows.append(\n",
    "            {'row_id': f'{df.id[idx]}_{(t + 1) * 5}' } | predictions\n",
    "        )\n",
    "\n",
    "sub = pd.DataFrame(inference_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184575141_5</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.049838</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184575141_10</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184575141_15</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.008117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184575141_20</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.267967</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184575141_25</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.002064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         row_id    asbfly   ashdro1   ashpri1   ashwoo2   asikoe2   asiope1  \\\n",
       "0   184575141_5  0.003141  0.049838  0.001311  0.000578  0.005712  0.000701   \n",
       "1  184575141_10  0.003231  0.017386  0.001354  0.000126  0.004948  0.000261   \n",
       "2  184575141_15  0.002194  0.003422  0.002339  0.000131  0.003646  0.000994   \n",
       "3  184575141_20  0.000671  0.001351  0.000405  0.000036  0.005262  0.000153   \n",
       "4  184575141_25  0.001910  0.005152  0.001600  0.000073  0.012563  0.000449   \n",
       "\n",
       "    aspfly1   aspswi1   barfly1  ...   whbwoo2   whcbar1   whiter2    whrmun  \\\n",
       "0  0.001039  0.000319  0.001783  ...  0.002819  0.010568  0.003517  0.000988   \n",
       "1  0.000825  0.001018  0.007044  ...  0.001455  0.001761  0.005326  0.001471   \n",
       "2  0.000484  0.000664  0.001037  ...  0.002878  0.002239  0.004384  0.000494   \n",
       "3  0.000474  0.000423  0.001712  ...  0.002648  0.267967  0.001925  0.000557   \n",
       "4  0.002295  0.000386  0.003738  ...  0.003120  0.604658  0.004617  0.001106   \n",
       "\n",
       "    whtkin2    woosan   wynlau1   yebbab1   yebbul3   zitcis1  \n",
       "0  0.007718  0.028587  0.000782  0.001914  0.001012  0.003750  \n",
       "1  0.005320  0.017342  0.000924  0.001708  0.000708  0.004110  \n",
       "2  0.003167  0.037133  0.000470  0.000470  0.000383  0.008117  \n",
       "3  0.001016  0.009322  0.000560  0.000238  0.001861  0.003404  \n",
       "4  0.001904  0.008089  0.004026  0.000323  0.006225  0.002064  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 AUC: 0.98153\n"
     ]
    }
   ],
   "source": [
    "if EVAL:\n",
    "    preds = sub[CLASSES].values\n",
    "    auc = macro_auc(df[\"primary_label\"].values.tolist(), preds)\n",
    "    print(f'Fold 0 AUC: {auc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
